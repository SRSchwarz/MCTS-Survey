\section{Introduction}
Monte Carlo Tree search (MCTS) is a sampling-based search algorithm for finding optimal decisions in a given domain by iteratively building a tree. It was first proposed by Chang et al. \cite{chang2005adaptive} and consecutively refined by Coloum \cite{coulom2006efficient} and Chaslot et al. \cite{chaslot2008monte}. MCTS has since distinguished itself by addressing the tradeoff known as the exploration-exploitation dilemma, offering a good balance between the exploration of new paths and the exploitation of known paths deemed to be promising. MCTS has become widely used in the domain of machine learning and especially in General Game Playing (GGP) because it performs well even in large domains and when no domain knowledge is available \cite{sironi2019comparing}. The most famous application of MCTS in this context is its usage as part of \textit{AlphaGo}: A neural network trained using MCTS that beat some of the worlds greatest human players in the game of Go -- something deemed impossible because of the sheer number of possible game states and the resulting size of the search space making the problem seem intractable with current methods \cite{silver2017mastering}.

The basic structure of MCTS is very simple. It is run in iterations until some condition is no longer satisfied, usually until a computational budget is exhausted. Each iteration consists of only four steps. Starting from the root node, i.e. the node representing the current state of the domain, the \textit{Tree Policy} is used to select a single new node and expand the existing tree. Now the \textit{default policy} is used to execute a simulation until a terminal state is reached. This state is now evaluated with respect to its reward. This reward is then backpropagated and used to update any statistics that are kept about the nodes involved. Details concerning the steps above are left up to the concrete implementation, the most popular being \textit{UCT} which models the node selection in step one as a \textit{Multi-Armed Bandit Problem} (MAB). This in turn allows for the utilization (and indeed reuse) of a variety of methods and analyses defined for MABs.

The algorithm can additionally be augmented by heuristics. A notable example of such an heuristic is \textit{All Moves as First} (AMAF) which was first proposed in the context of (again) Go and later combined with UCT by Gelly et al. \cite{gelly2007combining}. AMAF modifies which nodes are updated in each iteration by updating not only the selected node but also all nodes that are not chosen but used during the simulation. An idea that has been further extended by Gelly and Silver \cite{gelly2011monte} and Cazenave \cite{cazenave2015generalized} among others.

This paper is a survey of recent developments of modifications of the basic search algorithm and its use in domains inside as well as outside of computer science. It is structured as follows: Section \ref{sec:background} gives an overview of the concepts used and extended by MCTS as well as a detailed explanation of the algorithm itself and its most important use case in trees. Section \ref{sec:variations} presents variations of MCTS in five select categories. Then Section \ref{sec:use_cases} discusses the application of MCTS in various use cases. Finally, Section \ref{sec:conclusion} gives a summary of the paper and examines possible future research opportunities.

Due to the limited extend of this paper the overview is by no means exhaustive, there are scenarios and whole fields of modifications that are not mentioned at all. However, in the fields that are discussed an attempt was made to present work that is both prominent as well as representative of trends in research from 2013 to 2020. This paper can further be seen as an update of a 2012 survey by Browne et al. \cite{browne2012survey}.